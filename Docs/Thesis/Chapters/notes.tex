\unsure{daqui para baixo, é para reutilizar em outras secçoes e sair desta}
\section{My experience of flask quart and fastapi, add later somwhere}
  


  \subsection{FastAPI}
    Dependency injection can be of particular importance for maintainabilty and extensibility as we have already seen in the previous 
    sections with Flask extensions that were already integrated into the project, and that would have to be reimplemented from scratch 
    in Quart, were the project to go down that path. 
    
    Ultimately, the project transitioned to FastAPI. While the migration to FastAPI involved a fair amount of effort, this 
    was anticipated from the outset—unlike Quart, which had initially seemed easier but presented unforeseen difficulties, 
    it resulted in better runtime performance, improved concurrency handling, and a cleaner overall structure, when compared 
    to the previous Flask implementation with Celery integration.


\section{Asyncio more in depth}

  Asyncio is Python library for writing concurrent code. It provides a foundation for asynchronous programming by enabling 
  the creation and management of event loops, coroutines, and asynchronous tasks.

  An \textit{event loop} is a central component of asynchronous programming—it continuously runs in the background, managing 
  the execution of asynchronous tasks. When a task reaches a point where it would normally block (e.g., waiting for a network 
  response), it yields control back to the event loop, which can then continue running other ready tasks. This model of 
  cooperative multitasking contrasts with traditional multithreading or multiprocessing, as it operates in a single thread 
  and does not require locking or context switching between OS threads.

  A \textit{coroutine} is a special kind of function defined with \texttt{async def}. When called, it does not run immediately, 
  but instead returns a coroutine object. This object can be scheduled by the event loop, and when awaited, it runs until it 
  hits a pause point (e.g., another \texttt{await})—at which point it yields control back to the event loop, allowing other 
  coroutines to execute.

  For example, in FastAPI, declaring an endpoint as \texttt{async def} ensures that the underlying logic is non-blocking. 
  If that logic includes \texttt{asyncio}-compatible I/O operations—such as using a library for asynchronous \ac{http} calls 
  then the request can proceed in a truly asynchronous manner. This allows the web server to observe massive speedups when
  multiple \ac{http} calls must be made to external services.

  In the context of our project, \texttt{asyncio} plays a critical role. The application often performs multiple concurrent 
  \ac{http} requests to interact with services like \ac{gns3} and \ac{pve}. By utilizing asynchronous functions the application 
  can efficiently manage these concurrent tasks without spawning additional threads or processes, thus keeping overhead low.

  Additionally, \texttt{asyncio} supports the orchestration of multiple tasks using constructs such as \texttt{asyncio.gather()}, 
  which allows multiple coroutines to be executed concurrently and awaited collectively. This has been especially useful in 
  scenarios within the project where multiple devices or services must be queried or configured simultaneously.

\subsection{Celery}

  A Celery client running on a given machine will have allocated a set amount of workers to work on tasks. Workers are 
  independent processes that listen to the broker and execute incoming tasks concurrently. Tasks are Python functions that 
  are decorated with provided Celery decorators such as \texttt{@app.task}, causing them to be registered as Celery tasks 
  within the Celery application.

  \begin{algorithm}
    \caption{Calling a Celery Task and Getting the Result}\label{celery-call-result}
    \begin{algorithmic}[1]
      \State \textbf{from} celery \textbf{import} Celery
      \State
      \State \textbf{app} = Celery('tasks', broker='redis://localhost:6379/0', backend='redis://localhost:6379/0')
      \State
      \State \textbf{@app.task}
      \State \textbf{def} hello():
      \State \hspace{1em} \textbf{return} 'hello world'
      \State
      \State \textbf{result} = hello.delay()
      \State \textbf{print}(result.get())
    \end{algorithmic}
  \end{algorithm}

  To execute a task, a Celery task function must be called using the \textit{delay()} method, which will return a result object. 
  This result object can be used to check the status of the task and to retrieve the result once it is available.

  Celery supports horizontal scaling by design, allowing multiple worker pools to run on separate physical or virtual machines. 
  This makes it especially effective for handling growing workloads—for example, processing email newsletters for an expanding 
  user base.

  In addition to basic task execution, Celery provides advanced features such as retry policies, task chaining, prioritization, 
  and timeouts. However, these benefits come with added complexity in deployment and maintenance, especially regarding broker 
  reliability, result backend persistence, and worker supervision.

  Furthermore, Celery clients and workers introduce a non-negligible overhead in terms of CPU and memory usage, even when 
  idle, as they must maintain persistent connections to the broker and periodically perform health checks or heartbeats. 
  This can be a concern in resource-constrained environments or during development.This overhead became especially evident 
  during early integration tests.

  As the project evolved, it became increasingly clear that Celery's benefits did not outweigh its resource and 
  architectural costs for the current use case. This realization prompted an exploration of more lightweight asynchronous 
  alternatives, eventually culminating in a migration to FastAPI—an \ac{asgi}-compliant framework with native async capabilities 
  and simpler concurrency management.


\subsection{Requests}
  The Requests\cite{requests2025} library is a popular and user-friendly\ac{http} library for Python, used to send\ac{http} 
  requests to web services. It simplifies interactions with \ac{api}s by simple to use methods for the various\ac{http} verbs, 
  as well as providing support for cookies, sessions, authentication, \ac{json} and exception handling for network failures and 
  invalid responses.

  Requests was initially used in the project to handle all\ac{http} requests to the various services, such as
  \ac{gns3} and \ac{pve}. Its simplicity and ease of use made it a natural choice for the initial implementation, allowing
  for quick development and testing of the various endpoints.

  \begin{algorithm}
    \caption{Making a Synchronous HTTP Request Using Requests}\label{requests-basic}
    \begin{algorithmic}[1]
      \State \textbf{import} requests
      \State
      \State \textbf{url} = "https://api.example.com/data"
      \State \textbf{response} = requests.get(url)
      \State
      \If{response.status\_code == 200}
        \State \textbf{data} = response.json()
        \State \textbf{print}(data)
      \Else
        \State \textbf{print}("Request failed with status code", response.status\_code)
      \EndIf
    \end{algorithmic}
  \end{algorithm}

  However, as the project evolved and the need for asynchronous processing became more apparent, with Requests being a 
  synchronous library only, there was a need to transition to an alternative that support asynchronous operations.

\subsection{HTTPX}

  HTTPX\cite{httpx2025} is a modern \ac{http} client library for Python. HTTPX retains a similar structure to 
  Requests, while providing  built-in support for asyncio.

  In contrast to Requests, which blocks the current thread while waiting for a response, HTTPX enables non-blocking 
  \ac{http} communication when used in asynchronous mode. This is particularly beneficial in scenarios involving multiple 
  concurrent network operations, such as querying multiple \ac{gns3} devices or cloning virtual machines in \ac{pve}, 
  where synchronous requests would otherwise serialize execution and lead to performance bottlenecks.

  \begin{algorithm}
    \caption{Making an Asynchronous HTTP Request Using HTTPX}\label{httpx-basic}
    \begin{algorithmic}[1]
      \State \textbf{import} httpx
      \State \textbf{import} asyncio
      \State
      \State \textbf{async def} fetch():
      \State \hspace{1em} \textbf{url} = "https://api.example.com/data"
      \State \hspace{1em} \textbf{async with} httpx.AsyncClient() \textbf{as} client:
      \State \hspace{2em} response = \textbf{await} client.get(url)
      \State \hspace{2em} \textbf{if} response.status\_code == 200:
      \State \hspace{3em} \textbf{data} = response.json()
      \State \hspace{3em} \textbf{print}(data)
      \State \hspace{2em} \textbf{else}:
      \State \hspace{3em} \textbf{print}("Request failed with status code", response.status\_code)
      \State
      \State asyncio.run(fetch())
    \end{algorithmic}
  \end{algorithm}

  HTTPX was adopted in the project to replace Requests for both asynchronous and synchronous use cases. Thanks to its full 
  support for \texttt{async} and \texttt{await}, HTTPX integrates seamlessly into the FastAPI application, allowing 
  concurrent \ac{http} requests to be awaited collectively using constructs like \texttt{asyncio.gather()}. This significantly 
  improved the application's throughput under concurrent workloads.

  Overall, HTTPX provides a robust and flexible foundation for asynchronous networking in Python, making it an ideal 
  fit for the needs of this project.


\subsection{Linux}
  Linux is a core component of this project, as it is the kernel of all operating systems used to host all the services provided.

  \begin{itemize}
    \item \textbf{Containerized Web Application} - The web application is hosted in an \ac{lxc} on \ac{pve}. Since \ac{lxc}s share 
    the host kernel, the containerized web application benefits from efficient resource usage while still being isolated from the host system.
    \item \textbf{Virtual Machines hosting GNS3} \ac{pve} also hosts virtual machines running Linux-based Ubuntu \ac{gns3} servers. 
    These VMs provide students with environments to configure and test network topologies, benefiting from the 
    flexibility of full virtualization through \ac{kvm}, giving them the ability to virtualize any type of network device.
    Students only interact with these \ac{vm}s via the \ac{gns3} web Interface. Students interact with these \ac{vm}s using a browser, 
    accessing the gns3-server instance running on them. Consequently the students can interact with their work environments without having to 
    interact with the underlying operating system, and so these machines can forgo a desktop environment entirely, which frees up resources 
    leading to better scalability.
    \item \textbf{\ac{pve}} - \ac{pve} is a Linux-based open-source platform for enterprise-level virtualization. It is based
    on the Debian Linux distribution.
  \end{itemize}

\section{Implemented Features}

  The current proof-of-concept implementation delivers core functionality through the following capabilities:

  \subsection{User Management}
    \begin{itemize}
        \item \textbf{Registration}: Local account creation with credential storage
        \item \textbf{Authentication}: Hybrid login system supporting both:
        \begin{itemize}
            \item Local account credentials
            \item LDAP directory service integration
        \end{itemize}
    \end{itemize}

  \subsection{Exercise Workflow}
    \begin{itemize}
        \item \textbf{Exercise Enrollment}: Dynamic provisioning of per-user work environments
        \begin{itemize}
            \item Automatically creates GNS3 VM instances for enrolled users
            \item Associates VMs with specific exercise topologies
            \item Handles cleanup via VM deletion when users delist
        \end{itemize}
        \item \textbf{Exercise Creation}: Instructor interface for lab setup
        \begin{itemize}
            \item Accepts pre-configured GNS3 topology files (.gns3project)
            \item Configures validation commands per network device
        \end{itemize}
    \end{itemize}

  \subsection{Student Interaction}
    \begin{itemize}
        \item \textbf{VM Control}: Basic instance management
        \begin{itemize}
            \item Power on/off functionality for assigned work VMs
            \item Console access to network devices within the topology
        \end{itemize}
        \item \textbf{Configuration Validation}: Limited automated checking
        \begin{itemize}
            \item Supports ping and traceroute verification
            \item Processes instructor-defined test sequences
        \end{itemize}
    \end{itemize}

  \subsection{Current Technical Constraints}
    The system has intentional limitations in its current stage:
    \begin{itemize}
        \item Validation restricted to basic connectivity tests
        \item Static topology requirements (pre-built GNS3 projects)
        \item Manual evaluation triggering by students
        \item No performance benchmarking capabilities
    \end{itemize}

